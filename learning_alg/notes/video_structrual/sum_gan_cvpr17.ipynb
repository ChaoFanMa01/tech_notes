{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec9288a",
   "metadata": {},
   "source": [
    "# Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed17a6b",
   "metadata": {},
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c770bbb8",
   "metadata": {},
   "source": [
    "This paper addresses the problem of unsupervised video summarization, formulated as selecting a sparse subset of video frames that optimally represent the input video. Our key idea is to learn a deep summarizer network to minimize distance between training videos and a distribution of their summarizations, in an unsupervised way.\n",
    "\n",
    "The key frame selector is learned so as to minimize a distance between features extracted from the video and the selected key frames.\n",
    "\n",
    "We extract deep features from both the video and selected sequence of key frames using a cascade of a CNN and LSTM. The CNN is grouned onto pixels and extracts deep features from a given frame. The LSTM then fuses a sequence of the CNN's outputs for capturing long-range dependencies among the frames, and produces its own deep feature representing the input sequence. Specifically, we use the autoencoder LSTM as a suitable deep architecture for unsupervised learning of video features. Given a distance between the deep representations of the video and selected key frames, our goal is to optimize the frame selector such that this distance is minimized over training examples.\n",
    "\n",
    "We resort to the GAN, which extends the aforementioned video summarization network with an addtional discriminator network. The decoder part of the summarizer is used to reconstruct a video from the sequence of selected key frames. Then, we use a discriminator, which is another LSTM, to distinguish between the original video and its reconstruction from the summarizer. The auto-encoder LSTM and the frame selector are jointly trained so as to maximally confuse the discriminator LSTM-i.e., they cast ina role of the discriminator's adversary-such that the discriminator has a high error rate in recognizing between the original and reconstructed videos. When this recognition error becomes maximum, we deem that the frame selector is learned to produce optimal video summarizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04290fd8",
   "metadata": {},
   "source": [
    "### Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5b310",
   "metadata": {},
   "source": [
    "<img src=\"./figs/sum_gan_cvpr17_fig1.png\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89960cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce887b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2ecd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c70a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3caa3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2223f6f7",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13785056",
   "metadata": {},
   "source": [
    "[1] B. Mahasseni, M. Lam, and S. Todorovic, \"Unsupervised Video SUmmarization with Adversarial LSTM Networks,\" *in proc. IEEE CVPR'17*, pp. 202-211, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c6d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
