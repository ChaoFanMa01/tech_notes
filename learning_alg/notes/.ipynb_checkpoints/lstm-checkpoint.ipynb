{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `LSTM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM的结构如下图所示\n",
    "\n",
    "<img src=\"./figs/lstm1.png\" width=\"400px\" />\n",
    "\n",
    "PyTorch的官方文档中对`torch.nn.LSTM`的解释如下：\n",
    "\n",
    "Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. For **each** element in the input sequence, **each layer** computes the following function:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "i_t&=\\sigma(W_{ii}x_t+b_{ii}+W_{hi}h_{t-1}+b_{hi})\\\\\n",
    "f_t&=\\sigma(W_{if}x_t+b_{if}+W_{hf}h_{t-1}+b_{hf})\\\\\n",
    "g_t&=\\tanh(W_{ig}x_t+b_{ig}+W_{hg}h_{t-1}+b_{hg})\\\\\n",
    "o_t&=\\sigma(W_{io}x_t+b_{io}+W_{ho}h_{t-1}+b_{ho})\\\\\n",
    "c_t&=f_t\\odot c_{t-1}+i_t\\odot g_t\\\\\n",
    "h_t&=o_t\\odot \\tanh(c_t)\n",
    "\\end{split}\n",
    "$$\n",
    "where $h_t$ is the hidden state at time $t$, $c_t$ is the cell state at time $t$, $x_t$ is the input at time $t$, $h_{t-1}$ is the hidden state of the layer at time $t-1$ or the initial hidden state at time 0, and $i_t$, $f_t$, $g_t$ $o_t$ are the input, forget, cell, and output gates, respectively. $\\sigma$ is the sigmoid function, and $\\odot$ is the Hadamard product.\n",
    "\n",
    "上面是文档中对于单层LSTM的解释, 如果LSTM为多层, 则有以下附加说明\n",
    "\n",
    "In a **multilayer** LSTM, the input $x^{(l)}_t$ of the $l$-th layer ($l\\geq 2$) is the hidden state $h^{(l-1)}_t$ of the previous layer multiplied by dropout $\\delta^{(l-1)}_t$, where each $\\delta^{(l-1)}_t$ is a Bernoulli random variable which is 0 with probability `dropout`.\n",
    "\n",
    "另外一个会改变LSTM操作的参数是`proj_size`, 官方解释如下:\n",
    "\n",
    "If `proj_size`>0 is specified, LSTM with projections will be used. This changes the LSTM cell in the following way. First, the dimension of $h_t$ will be changed from `hidden_size` to `proj_size` (dimension of $W_{hi}$ will be changed accordingly). Second, the output hidden state of each layer will be multiplied by a learnable projection matrix: $h_t=W_{hr}h_t$. Note that as a consequence of this, the output of LSTM network will be of different shape as well.\n",
    "\n",
    "`torch.nn.LSTM`各参数含义如下：\n",
    "\n",
    "- `input_size` – The number of expected features in the input $x$.\n",
    "- `hidden_size` – The number of features in the hidden state $h$.\n",
    "- `num_layers` – Number of recurrent layers. E.g., setting `num_layers=2` would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1.\n",
    "- `bias` – If `False`, then the layer does not use bias weights $b_ih$ and $b_hh$. Default: `True`.\n",
    "- `batch_first` – If True, then the input and output tensors are provided as $(batch, seq, feature)$ instead of $(seq, batch, feature)$. Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details. Default: `False`.\n",
    "- `dropout` – If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0.\n",
    "- `bidirectional` – If True, becomes a bidirectional LSTM. Default: `False`.\n",
    "- `proj_size` – If > 0, will use LSTM with projections of corresponding size. Default: 0.\n",
    "\n",
    "模型输入数据含义如下:\n",
    "\n",
    ">Inputs: `input`, (`h_0`, `c_0`)\n",
    "\n",
    "- `input`: tensor of shape $(L,H_{in})$ for unbatched input, $(L, N, H_{in})$ when `batch_first=False` or $(N,L,H_{in})$ when `batch_first=True` containing the features of the input sequence.\n",
    "- `h_0`: tensor of shape $(D\\times num\\_layers, H_{out})$ for unbatched input or $(D\\times num\\_layers, N, H_{out})$ containing the initial hidden state for each element in the input sequence. Defaults to zeros if (`c_0`, `h_0`) is not provided.\n",
    "- `c_0`: tensor of shape $(D\\times num\\_layers,H_{cell})$ for unbatched input or $(D\\times num\\_layers,N,H_{cell})$ containing the initial cell state for each element in the input sequence. Defaults to zeros if (`c_0`, `h_0`) is not provided.\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "N&=\\text{batch size}\\\\\n",
    "L&=\\text{sequence length}\\\\\n",
    "D&=\\text{2 if bidirectional=True otherwise 1}\\\\\n",
    "H_{in}&=\\text{input\\_size}\\\\\n",
    "H_{cell}&=\\text{hidden\\_size}\\\\\n",
    "H_{out}&=\\text{proj\\_size if proj\\_size>0 otherwise hidden\\_size}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "模型输出数据含义如下:\n",
    "\n",
    ">Output: `output`, (`h_n`, `c_n`)\n",
    "\n",
    "- `output`: tensor of shape $(L, D\\times H_{out})$ for unbatched input, $(L,N,D\\times H_{out})$ when `batch_first=False` or $(N,L,D\\times H_{out})$ when `batch_first=True` containing the output features (*h_t*) from the **last layer** of the LSTM, for each $t$ (就是最后一层的隐含层特征). \n",
    "- `h_n`: tensor of shape $(D\\times num\\_layers, H_{out})$ for unbatched input or $(D\\times num\\_layers,N, H_{out})$ containing the final hidden state for each element in the sequence. When `bidirectional = True`, `h_n` will contain a concatenation of the final forward and reverse hidden states, respectively.\n",
    "- `c_n`: tensor of shape $(D\\times num\\_layers, H_{cell})$ for unbatched input or $(D\\times num\\_layers, N, H_{cell})$ containing the final cell state for each element in the sequence. When `bidirectional = True`, `c_n` will contain a concatenation of the final forward and reverse hidden states, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `LSTMCell`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LSTMCell` is a LSTM cell.\n",
    "\n",
    ">`torch.nn.LSTMCell`(`input_size`,`hidden_size`, `bias=True`, `device=None`, `dtype=None`)\n",
    "$$\n",
    "\\begin{split}\n",
    "i&=\\sigma(W_{ii}x+b_{ii}+W_{hi}h+b_{hi})\\\\\n",
    "f&=\\sigma(W_{if}x+b_{if}+W_{hf}h+b_{hf})\\\\\n",
    "g&=\\tanh(W_{ig}x+b_{ig}+W_{hg}h+b_{hg})\\\\\n",
    "o&=\\sigma(W_{io}x+b_{io}+W_{ho}h+b_{ho})\\\\\n",
    "c'&=f\\odot c+i\\odot g\\\\\n",
    "h'&=o\\odot \\tanh(c')\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "各参数含义如下:\n",
    "\n",
    "- `input_size(int)`-The number of expected features in the input $x$.\n",
    "- `hidden_size(int)`-The number of features in the hidden state $h$.\n",
    "- `bias(bool)`-If `Flase`, then the layer does not use bias weight $b_{ih}$ and $b_{hh}$. Default: `True`.\n",
    "\n",
    "输入数据含义如下:\n",
    "\n",
    ">Inputs:`input`, `(h_0,c_0)`\n",
    "\n",
    "- `input`: tensor of shape ($batch,input\\_size$) or ($input\\_size$): tensor containing input features.\n",
    "- `h_0`: tensor of shape ($batch,hidden\\_size$) or ($hidden\\_size$): tensor containing the initial hidden state.\n",
    "- `c_0`: tensor of shape ($batch, hidden\\_size$) or ($hidden\\_size$): tensor containing the initial cell state.\n",
    "\n",
    "If (`h_0`, `c_0`) is not provided, both `h_0` and `c_0` default to zero.\n",
    "\n",
    "输出数据含义如下:\n",
    "\n",
    ">Outputs:(`h_1`, `c_1`)\n",
    "\n",
    "- `h_1`: tensor of shape ($batch,hidden\\_size$) or ($hidden\\_size$): tensor containing the next hidden state.\n",
    "- `c_1`: tensor of shape ($batch,hidden\\_size$) or ($hidden\\_size$): tensor containing the next cell state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle金价预测数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This DataSet includes the real time gold prices(in USD) from 2012 to 2022 [1].\n",
    "\n",
    "数据集中各字段含义如下:\n",
    "\n",
    "- **Date**: Date on which Price is Noted\n",
    "- **Close**: Close Price of the Gold in USD\n",
    "- **Volume**: Sum of buy's and sell's of Gold Commodity\n",
    "- **open**: open price of a Gold on that particular day\n",
    "- **High**: High price of Gold on that particular day\n",
    "- **Low**: Low price of Gold on that particular day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `LSTM`预测金价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2547 entries, 0 to 2546\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Date        2547 non-null   object \n",
      " 1   Close/Last  2547 non-null   float64\n",
      " 2   Volume      2508 non-null   float64\n",
      " 3   Open        2547 non-null   float64\n",
      " 4   High        2547 non-null   float64\n",
      " 5   Low         2547 non-null   float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 119.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "DIR = '~/prj/tech_notes/learning_alg/src/data/'\n",
    "fname = 'kaggle_gold_price_prediction.csv'\n",
    "\n",
    "dataset = pd.read_csv(os.path.join(DIR, fname))\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close/Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>10/31/2012</td>\n",
       "      <td>1719.1</td>\n",
       "      <td>110928.0</td>\n",
       "      <td>1710.3</td>\n",
       "      <td>1726.6</td>\n",
       "      <td>1709.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>11/01/2012</td>\n",
       "      <td>1715.5</td>\n",
       "      <td>105904.0</td>\n",
       "      <td>1720.4</td>\n",
       "      <td>1727.5</td>\n",
       "      <td>1715.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>11/02/2012</td>\n",
       "      <td>1675.2</td>\n",
       "      <td>205777.0</td>\n",
       "      <td>1715.6</td>\n",
       "      <td>1717.2</td>\n",
       "      <td>1674.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>11/05/2012</td>\n",
       "      <td>1683.2</td>\n",
       "      <td>109647.0</td>\n",
       "      <td>1676.7</td>\n",
       "      <td>1686.2</td>\n",
       "      <td>1672.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>11/06/2012</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>163585.0</td>\n",
       "      <td>1685.4</td>\n",
       "      <td>1720.9</td>\n",
       "      <td>1683.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/24/2022</td>\n",
       "      <td>1654.1</td>\n",
       "      <td>167448.0</td>\n",
       "      <td>1662.9</td>\n",
       "      <td>1675.5</td>\n",
       "      <td>1648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/25/2022</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>178706.0</td>\n",
       "      <td>1654.5</td>\n",
       "      <td>1666.8</td>\n",
       "      <td>1641.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/26/2022</td>\n",
       "      <td>1669.2</td>\n",
       "      <td>183453.0</td>\n",
       "      <td>1657.7</td>\n",
       "      <td>1679.4</td>\n",
       "      <td>1653.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/27/2022</td>\n",
       "      <td>1668.8</td>\n",
       "      <td>180599.0</td>\n",
       "      <td>1668.8</td>\n",
       "      <td>1674.8</td>\n",
       "      <td>1658.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/28/2022</td>\n",
       "      <td>1648.3</td>\n",
       "      <td>186519.0</td>\n",
       "      <td>1667.2</td>\n",
       "      <td>1670.9</td>\n",
       "      <td>1640.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2547 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Close/Last    Volume    Open    High     Low\n",
       "2546  10/31/2012      1719.1  110928.0  1710.3  1726.6  1709.8\n",
       "2545  11/01/2012      1715.5  105904.0  1720.4  1727.5  1715.1\n",
       "2544  11/02/2012      1675.2  205777.0  1715.6  1717.2  1674.8\n",
       "2543  11/05/2012      1683.2  109647.0  1676.7  1686.2  1672.5\n",
       "2542  11/06/2012      1715.0  163585.0  1685.4  1720.9  1683.5\n",
       "...          ...         ...       ...     ...     ...     ...\n",
       "4     10/24/2022      1654.1  167448.0  1662.9  1675.5  1648.0\n",
       "3     10/25/2022      1658.0  178706.0  1654.5  1666.8  1641.2\n",
       "2     10/26/2022      1669.2  183453.0  1657.7  1679.4  1653.8\n",
       "1     10/27/2022      1668.8  180599.0  1668.8  1674.8  1658.5\n",
       "0     10/28/2022      1648.3  186519.0  1667.2  1670.9  1640.7\n",
       "\n",
       "[2547 rows x 6 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据时间倒序排列.\n",
    "dataset = dataset.sort_index(axis = 0, ascending = False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据清洗. `Volume`属性中含有空值, 本次实验用均值进行填充."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2547 entries, 2546 to 0\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Date        2547 non-null   object \n",
      " 1   Close/Last  2547 non-null   float64\n",
      " 2   Volume      2547 non-null   float64\n",
      " 3   Open        2547 non-null   float64\n",
      " 4   High        2547 non-null   float64\n",
      " 5   Low         2547 non-null   float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 139.3+ KB\n"
     ]
    }
   ],
   "source": [
    "mean = dataset['Volume'].mean()\n",
    "dataset['Volume'].fillna(mean, inplace = True)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标为预测收市价. 因此，将`Close/Last`作为标签, 并将除`Date`外的字段作为特征输入模型. 本次实验将前2500天作为训练集, 后47天作为测试集."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close/Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>10/31/2012</td>\n",
       "      <td>1719.1</td>\n",
       "      <td>110928.0</td>\n",
       "      <td>1710.3</td>\n",
       "      <td>1726.6</td>\n",
       "      <td>1709.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>11/01/2012</td>\n",
       "      <td>1715.5</td>\n",
       "      <td>105904.0</td>\n",
       "      <td>1720.4</td>\n",
       "      <td>1727.5</td>\n",
       "      <td>1715.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>11/02/2012</td>\n",
       "      <td>1675.2</td>\n",
       "      <td>205777.0</td>\n",
       "      <td>1715.6</td>\n",
       "      <td>1717.2</td>\n",
       "      <td>1674.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>11/05/2012</td>\n",
       "      <td>1683.2</td>\n",
       "      <td>109647.0</td>\n",
       "      <td>1676.7</td>\n",
       "      <td>1686.2</td>\n",
       "      <td>1672.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>11/06/2012</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>163585.0</td>\n",
       "      <td>1685.4</td>\n",
       "      <td>1720.9</td>\n",
       "      <td>1683.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>08/17/2022</td>\n",
       "      <td>1776.7</td>\n",
       "      <td>134521.0</td>\n",
       "      <td>1790.8</td>\n",
       "      <td>1796.6</td>\n",
       "      <td>1773.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>08/18/2022</td>\n",
       "      <td>1771.2</td>\n",
       "      <td>119686.0</td>\n",
       "      <td>1777.1</td>\n",
       "      <td>1786.3</td>\n",
       "      <td>1768.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>08/19/2022</td>\n",
       "      <td>1762.9</td>\n",
       "      <td>133714.0</td>\n",
       "      <td>1773.1</td>\n",
       "      <td>1773.3</td>\n",
       "      <td>1759.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>08/22/2022</td>\n",
       "      <td>1748.4</td>\n",
       "      <td>137883.0</td>\n",
       "      <td>1760.6</td>\n",
       "      <td>1762.1</td>\n",
       "      <td>1740.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>08/23/2022</td>\n",
       "      <td>1761.2</td>\n",
       "      <td>140603.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1767.5</td>\n",
       "      <td>1743.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Close/Last    Volume    Open    High     Low\n",
       "2546  10/31/2012      1719.1  110928.0  1710.3  1726.6  1709.8\n",
       "2545  11/01/2012      1715.5  105904.0  1720.4  1727.5  1715.1\n",
       "2544  11/02/2012      1675.2  205777.0  1715.6  1717.2  1674.8\n",
       "2543  11/05/2012      1683.2  109647.0  1676.7  1686.2  1672.5\n",
       "2542  11/06/2012      1715.0  163585.0  1685.4  1720.9  1683.5\n",
       "...          ...         ...       ...     ...     ...     ...\n",
       "51    08/17/2022      1776.7  134521.0  1790.8  1796.6  1773.9\n",
       "50    08/18/2022      1771.2  119686.0  1777.1  1786.3  1768.8\n",
       "49    08/19/2022      1762.9  133714.0  1773.1  1773.3  1759.1\n",
       "48    08/22/2022      1748.4  137883.0  1760.6  1762.1  1740.2\n",
       "47    08/23/2022      1761.2  140603.0  1750.0  1767.5  1743.1\n",
       "\n",
       "[2500 rows x 6 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = dataset[:2500]\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close/Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>08/24/2022</td>\n",
       "      <td>1761.5</td>\n",
       "      <td>111405.00000</td>\n",
       "      <td>1761.3</td>\n",
       "      <td>1769.5</td>\n",
       "      <td>1754.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>08/25/2022</td>\n",
       "      <td>1771.4</td>\n",
       "      <td>114539.00000</td>\n",
       "      <td>1764.4</td>\n",
       "      <td>1778.8</td>\n",
       "      <td>1763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>08/26/2022</td>\n",
       "      <td>1749.8</td>\n",
       "      <td>169654.00000</td>\n",
       "      <td>1771.8</td>\n",
       "      <td>1772.3</td>\n",
       "      <td>1746.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>08/29/2022</td>\n",
       "      <td>1749.7</td>\n",
       "      <td>151838.00000</td>\n",
       "      <td>1748.4</td>\n",
       "      <td>1757.9</td>\n",
       "      <td>1731.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>08/30/2022</td>\n",
       "      <td>1736.3</td>\n",
       "      <td>126018.00000</td>\n",
       "      <td>1749.8</td>\n",
       "      <td>1752.8</td>\n",
       "      <td>1732.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>08/31/2022</td>\n",
       "      <td>1726.2</td>\n",
       "      <td>169549.00000</td>\n",
       "      <td>1735.5</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>1720.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>09/01/2022</td>\n",
       "      <td>1709.3</td>\n",
       "      <td>192532.00000</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>1699.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>09/02/2022</td>\n",
       "      <td>1722.6</td>\n",
       "      <td>171140.00000</td>\n",
       "      <td>1707.8</td>\n",
       "      <td>1729.5</td>\n",
       "      <td>1705.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>09/06/2022</td>\n",
       "      <td>1712.9</td>\n",
       "      <td>202021.00000</td>\n",
       "      <td>1724.2</td>\n",
       "      <td>1737.4</td>\n",
       "      <td>1710.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>09/07/2022</td>\n",
       "      <td>1727.8</td>\n",
       "      <td>169690.00000</td>\n",
       "      <td>1712.9</td>\n",
       "      <td>1731.2</td>\n",
       "      <td>1701.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>09/08/2022</td>\n",
       "      <td>1720.2</td>\n",
       "      <td>182302.00000</td>\n",
       "      <td>1729.5</td>\n",
       "      <td>1739.4</td>\n",
       "      <td>1713.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>09/09/2022</td>\n",
       "      <td>1728.6</td>\n",
       "      <td>151576.00000</td>\n",
       "      <td>1719.6</td>\n",
       "      <td>1740.5</td>\n",
       "      <td>1719.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>09/12/2022</td>\n",
       "      <td>1740.6</td>\n",
       "      <td>152588.00000</td>\n",
       "      <td>1728.4</td>\n",
       "      <td>1746.4</td>\n",
       "      <td>1722.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>09/13/2022</td>\n",
       "      <td>1717.4</td>\n",
       "      <td>228966.00000</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>1742.9</td>\n",
       "      <td>1706.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>09/14/2022</td>\n",
       "      <td>1709.1</td>\n",
       "      <td>159797.00000</td>\n",
       "      <td>1711.6</td>\n",
       "      <td>1717.3</td>\n",
       "      <td>1703.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>09/15/2022</td>\n",
       "      <td>1677.3</td>\n",
       "      <td>257001.00000</td>\n",
       "      <td>1707.2</td>\n",
       "      <td>1707.8</td>\n",
       "      <td>1668.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>09/16/2022</td>\n",
       "      <td>1683.5</td>\n",
       "      <td>209506.00000</td>\n",
       "      <td>1673.7</td>\n",
       "      <td>1689.9</td>\n",
       "      <td>1661.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>09/19/2022</td>\n",
       "      <td>1678.2</td>\n",
       "      <td>138336.00000</td>\n",
       "      <td>1685.4</td>\n",
       "      <td>1688.8</td>\n",
       "      <td>1667.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>09/20/2022</td>\n",
       "      <td>1671.1</td>\n",
       "      <td>140765.00000</td>\n",
       "      <td>1684.9</td>\n",
       "      <td>1688.8</td>\n",
       "      <td>1668.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>09/21/2022</td>\n",
       "      <td>1675.7</td>\n",
       "      <td>221902.00000</td>\n",
       "      <td>1673.2</td>\n",
       "      <td>1696.9</td>\n",
       "      <td>1661.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>09/22/2022</td>\n",
       "      <td>1681.1</td>\n",
       "      <td>232407.00000</td>\n",
       "      <td>1682.8</td>\n",
       "      <td>1693.5</td>\n",
       "      <td>1663.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>09/23/2022</td>\n",
       "      <td>1655.6</td>\n",
       "      <td>236570.00000</td>\n",
       "      <td>1680.1</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>1646.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>09/26/2022</td>\n",
       "      <td>1633.4</td>\n",
       "      <td>213873.00000</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>1657.2</td>\n",
       "      <td>1627.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>09/27/2022</td>\n",
       "      <td>1636.2</td>\n",
       "      <td>192565.00000</td>\n",
       "      <td>1629.2</td>\n",
       "      <td>1650.1</td>\n",
       "      <td>1628.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>09/28/2022</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>270952.00000</td>\n",
       "      <td>1636.5</td>\n",
       "      <td>1671.6</td>\n",
       "      <td>1622.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>09/29/2022</td>\n",
       "      <td>1668.6</td>\n",
       "      <td>196633.00000</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>1673.1</td>\n",
       "      <td>1649.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>09/30/2022</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>173144.00000</td>\n",
       "      <td>1669.5</td>\n",
       "      <td>1684.4</td>\n",
       "      <td>1667.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10/03/2022</td>\n",
       "      <td>1702.0</td>\n",
       "      <td>207858.00000</td>\n",
       "      <td>1670.5</td>\n",
       "      <td>1710.4</td>\n",
       "      <td>1666.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10/04/2022</td>\n",
       "      <td>1730.5</td>\n",
       "      <td>199426.00000</td>\n",
       "      <td>1708.4</td>\n",
       "      <td>1738.7</td>\n",
       "      <td>1704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10/05/2022</td>\n",
       "      <td>1720.8</td>\n",
       "      <td>168000.00000</td>\n",
       "      <td>1734.4</td>\n",
       "      <td>1736.6</td>\n",
       "      <td>1708.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10/06/2022</td>\n",
       "      <td>1720.9</td>\n",
       "      <td>134333.00000</td>\n",
       "      <td>1725.5</td>\n",
       "      <td>1734.2</td>\n",
       "      <td>1714.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10/07/2022</td>\n",
       "      <td>1709.3</td>\n",
       "      <td>153813.00000</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>1722.8</td>\n",
       "      <td>1698.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10/10/2022</td>\n",
       "      <td>1675.2</td>\n",
       "      <td>152626.00000</td>\n",
       "      <td>1703.4</td>\n",
       "      <td>1707.4</td>\n",
       "      <td>1672.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10/11/2022</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>166065.00000</td>\n",
       "      <td>1675.6</td>\n",
       "      <td>1691.3</td>\n",
       "      <td>1667.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10/12/2022</td>\n",
       "      <td>1677.5</td>\n",
       "      <td>127689.00000</td>\n",
       "      <td>1673.4</td>\n",
       "      <td>1685.1</td>\n",
       "      <td>1668.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10/13/2022</td>\n",
       "      <td>1672.9</td>\n",
       "      <td>182067.66866</td>\n",
       "      <td>1672.9</td>\n",
       "      <td>1672.9</td>\n",
       "      <td>1672.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10/14/2022</td>\n",
       "      <td>1672.9</td>\n",
       "      <td>182067.66866</td>\n",
       "      <td>1672.9</td>\n",
       "      <td>1672.9</td>\n",
       "      <td>1672.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10/17/2022</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>144374.00000</td>\n",
       "      <td>1649.9</td>\n",
       "      <td>1674.3</td>\n",
       "      <td>1649.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10/18/2022</td>\n",
       "      <td>1655.5</td>\n",
       "      <td>182067.66866</td>\n",
       "      <td>1655.5</td>\n",
       "      <td>1655.5</td>\n",
       "      <td>1655.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10/19/2022</td>\n",
       "      <td>1634.2</td>\n",
       "      <td>172551.00000</td>\n",
       "      <td>1657.2</td>\n",
       "      <td>1659.8</td>\n",
       "      <td>1632.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10/20/2022</td>\n",
       "      <td>1636.8</td>\n",
       "      <td>159797.00000</td>\n",
       "      <td>1634.6</td>\n",
       "      <td>1650.3</td>\n",
       "      <td>1626.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10/21/2022</td>\n",
       "      <td>1656.3</td>\n",
       "      <td>265985.00000</td>\n",
       "      <td>1632.4</td>\n",
       "      <td>1663.1</td>\n",
       "      <td>1621.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/24/2022</td>\n",
       "      <td>1654.1</td>\n",
       "      <td>167448.00000</td>\n",
       "      <td>1662.9</td>\n",
       "      <td>1675.5</td>\n",
       "      <td>1648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/25/2022</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>178706.00000</td>\n",
       "      <td>1654.5</td>\n",
       "      <td>1666.8</td>\n",
       "      <td>1641.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/26/2022</td>\n",
       "      <td>1669.2</td>\n",
       "      <td>183453.00000</td>\n",
       "      <td>1657.7</td>\n",
       "      <td>1679.4</td>\n",
       "      <td>1653.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/27/2022</td>\n",
       "      <td>1668.8</td>\n",
       "      <td>180599.00000</td>\n",
       "      <td>1668.8</td>\n",
       "      <td>1674.8</td>\n",
       "      <td>1658.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/28/2022</td>\n",
       "      <td>1648.3</td>\n",
       "      <td>186519.00000</td>\n",
       "      <td>1667.2</td>\n",
       "      <td>1670.9</td>\n",
       "      <td>1640.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Close/Last        Volume    Open    High     Low\n",
       "46  08/24/2022      1761.5  111405.00000  1761.3  1769.5  1754.8\n",
       "45  08/25/2022      1771.4  114539.00000  1764.4  1778.8  1763.0\n",
       "44  08/26/2022      1749.8  169654.00000  1771.8  1772.3  1746.2\n",
       "43  08/29/2022      1749.7  151838.00000  1748.4  1757.9  1731.4\n",
       "42  08/30/2022      1736.3  126018.00000  1749.8  1752.8  1732.9\n",
       "41  08/31/2022      1726.2  169549.00000  1735.5  1738.0  1720.6\n",
       "40  09/01/2022      1709.3  192532.00000  1723.0  1723.0  1699.1\n",
       "39  09/02/2022      1722.6  171140.00000  1707.8  1729.5  1705.9\n",
       "38  09/06/2022      1712.9  202021.00000  1724.2  1737.4  1710.6\n",
       "37  09/07/2022      1727.8  169690.00000  1712.9  1731.2  1701.7\n",
       "36  09/08/2022      1720.2  182302.00000  1729.5  1739.4  1713.7\n",
       "35  09/09/2022      1728.6  151576.00000  1719.6  1740.5  1719.4\n",
       "34  09/12/2022      1740.6  152588.00000  1728.4  1746.4  1722.3\n",
       "33  09/13/2022      1717.4  228966.00000  1736.0  1742.9  1706.7\n",
       "32  09/14/2022      1709.1  159797.00000  1711.6  1717.3  1703.3\n",
       "31  09/15/2022      1677.3  257001.00000  1707.2  1707.8  1668.9\n",
       "30  09/16/2022      1683.5  209506.00000  1673.7  1689.9  1661.9\n",
       "29  09/19/2022      1678.2  138336.00000  1685.4  1688.8  1667.6\n",
       "28  09/20/2022      1671.1  140765.00000  1684.9  1688.8  1668.1\n",
       "27  09/21/2022      1675.7  221902.00000  1673.2  1696.9  1661.3\n",
       "26  09/22/2022      1681.1  232407.00000  1682.8  1693.5  1663.3\n",
       "25  09/23/2022      1655.6  236570.00000  1680.1  1685.0  1646.6\n",
       "24  09/26/2022      1633.4  213873.00000  1651.0  1657.2  1627.7\n",
       "23  09/27/2022      1636.2  192565.00000  1629.2  1650.1  1628.7\n",
       "22  09/28/2022      1670.0  270952.00000  1636.5  1671.6  1622.2\n",
       "21  09/29/2022      1668.6  196633.00000  1669.0  1673.1  1649.3\n",
       "20  09/30/2022      1672.0  173144.00000  1669.5  1684.4  1667.5\n",
       "19  10/03/2022      1702.0  207858.00000  1670.5  1710.4  1666.5\n",
       "18  10/04/2022      1730.5  199426.00000  1708.4  1738.7  1704.0\n",
       "17  10/05/2022      1720.8  168000.00000  1734.4  1736.6  1708.8\n",
       "16  10/06/2022      1720.9  134333.00000  1725.5  1734.2  1714.8\n",
       "15  10/07/2022      1709.3  153813.00000  1721.0  1722.8  1698.4\n",
       "14  10/10/2022      1675.2  152626.00000  1703.4  1707.4  1672.5\n",
       "13  10/11/2022      1686.0  166065.00000  1675.6  1691.3  1667.5\n",
       "12  10/12/2022      1677.5  127689.00000  1673.4  1685.1  1668.0\n",
       "11  10/13/2022      1672.9  182067.66866  1672.9  1672.9  1672.9\n",
       "10  10/14/2022      1672.9  182067.66866  1672.9  1672.9  1672.9\n",
       "9   10/17/2022      1664.0  144374.00000  1649.9  1674.3  1649.1\n",
       "8   10/18/2022      1655.5  182067.66866  1655.5  1655.5  1655.5\n",
       "7   10/19/2022      1634.2  172551.00000  1657.2  1659.8  1632.2\n",
       "6   10/20/2022      1636.8  159797.00000  1634.6  1650.3  1626.3\n",
       "5   10/21/2022      1656.3  265985.00000  1632.4  1663.1  1621.1\n",
       "4   10/24/2022      1654.1  167448.00000  1662.9  1675.5  1648.0\n",
       "3   10/25/2022      1658.0  178706.00000  1654.5  1666.8  1641.2\n",
       "2   10/26/2022      1669.2  183453.00000  1657.7  1679.4  1653.8\n",
       "1   10/27/2022      1668.8  180599.00000  1668.8  1674.8  1658.5\n",
       "0   10/28/2022      1648.3  186519.00000  1667.2  1670.9  1640.7"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = dataset[2500:]\n",
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义数据迭代器."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def data_iter(data, time_step, batch_size):\n",
    "    '''\n",
    "    output shape (time_step, batch_size, feature_size)\n",
    "    '''\n",
    "    end_index = len(data) - time_step - 1\n",
    "    sample_indices = [list(range(end_index)) for i in range(batch_size)]\n",
    "    for i in range(batch_size):\n",
    "        random.shuffle(sample_indices[i])\n",
    "    cpy = data.copy()\n",
    "    for i in range(end_index):\n",
    "        features, labels = [], []\n",
    "        for j in range(time_step):\n",
    "            features.append([data.iloc[sample_indices[k][j]].to_numpy() for k in range(batch_size)])\n",
    "            labels.append([data['Close/Last'][sample_indices[k][j + 1]] for k in range(batch_size)])\n",
    "        features, labels = np.array(features), np.array(labels)\n",
    "        yield (torch.tensor(features, dtype = torch.float32), torch.tensor(labels, dtype = torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LSTMPred(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch_size, bidirection = False):\n",
    "        super(LSTMPred, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.D = 1 if bidirection is False else 2\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        self.state = None\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.state = (\n",
    "            torch.zeros(self.D * self.num_layers, self.batch_size, self.hidden_size),\n",
    "            torch.zeros(self.D * self.num_layers, self.batch_size, self.hidden_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out, self.state = self.lstm(X, self.state)\n",
    "        out = self.linear(out.view(-1, out.shape[-1]))\n",
    "        return out, self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_set, num_epochs, lr):\n",
    "    loss = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "    time_step, batch_size = model.time_step, model.batch_size\n",
    "    for X, Y in data_iter(train_set, time_step, batch_size):\n",
    "        model.reset_state()\n",
    "        pred, model.state = model(X, model.state)\n",
    "        # `pred`的形状为(batch_size * time_step, 1), 而`Y`的形状\n",
    "        # 为(time_step, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://www.kaggle.com/datasets/saikumartamminana/gold-price-prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
